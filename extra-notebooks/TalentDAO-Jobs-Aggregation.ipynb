{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def csvFolderToDataframe(path):\n",
    "    all_files = glob.glob(os.path.join(path , \"*.csv\"))\n",
    "    \n",
    "    li = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return frame\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=1):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGetro():\n",
    "    frame = csvFolderToDataframe(r'D:\\GitHub\\crypto-jobs-scraper\\node-scraper\\data\\getro')\n",
    "    deduplicated = (frame.drop_duplicates(subset='Job Link', keep='first', inplace=False)\n",
    "                    .drop_duplicates(subset='Getro ObjectID', keep='first', inplace=False))\n",
    "\n",
    "    header = [\"Company Name\", \"Job Link\", \"Job Location\", \"Job Title\", \"Salary Range\", \"Tags\", \"Posted Before\"]\n",
    "    deduplicated.to_csv(r'D:\\GitHub\\crypto-jobs-scraper\\data\\getro\\all_jobs.csv', columns = header, index=False)\n",
    "    return deduplicated\n",
    "    \n",
    "getro = processGetro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processConsider():\n",
    "    frame = csvFolderToDataframe(r'D:\\GitHub\\crypto-jobs-scraper\\node-scraper\\data\\consider')\n",
    "    deduplicated = (frame.drop_duplicates(subset='Job Link', keep='first', inplace=False)\n",
    "                    .drop_duplicates(subset='Consider JobID', keep='first', inplace=False))\n",
    "    header = [\"Company Name\", \"Job Link\", \"Job Location\", \"Job Title\", \"Salary Range\", \"Tags\", \"Posted Before\"]\n",
    "    deduplicated.to_csv(r'D:\\GitHub\\crypto-jobs-scraper\\data\\consider\\all_jobs.csv', columns = header, index=False)\n",
    "    return deduplicated\n",
    "    \n",
    "consider = processConsider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "web3Career = csvFolderToDataframe(path = r'D:\\GitHub\\crypto-jobs-scraper\\data\\web3_careers\\page_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptoJobsList = pd.read_csv(r'D:\\GitHub\\crypto-jobs-scraper\\data\\crypto_jobs_list\\all_jobs.csv', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7085, 10) (1584, 10) (17458, 7) (268, 4)\n"
     ]
    }
   ],
   "source": [
    "print(getro.shape, consider.shape, web3Career.shape, cryptoJobsList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "getroAndConsiderJobs = pd.concat([getro, consider])\n",
    "header = [\"Company Name\", \"Job Link\", \"Job Location\", \"Job Title\", \"Salary Range\", \"Tags\", \"Posted Before\"]\n",
    "vcBoardJobs = getroAndConsiderJobs.drop_duplicates(subset='Job Link', keep='first', inplace=False)[header]\n",
    "vcBoardJobs.to_csv(r'D:\\GitHub\\crypto-jobs-scraper\\data\\vc-job-boards\\all_jobs.csv', columns = header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedJobs = pd.concat([vcBoardJobs, web3Career, cryptoJobsList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "allJobs = concatenatedJobs.drop_duplicates(subset='Job Link', keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25781, 7) (25514, 7)\n"
     ]
    }
   ],
   "source": [
    "print(concatenatedJobs.shape, allJobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 100 Blockchain Companies (from Crunchbase)\n",
    "top100Companies = [\"Coinbase\",\"CoinDCX\",\"Animoca Brands\",\"Polygon\",\"CertiK\",\"CoinList\",\"NYDIG\",\"Axie Infinity\",\"Terra\",\"OpenSea\",\"Argent\",\"LayerZero Labs\",\"Algorand\",\"Helium\",\"Blockdaemon\",\"NEAR Protocol\",\"DFINITY\",\"2TM\",\"Circle\",\"21Shares\",\"StarkWare Industries\",\"Celsius Network\",\"Figment\",\"0x\",\"Securitize\",\"Ava Labs\",\"Brave\",\"5ire\",\"Ethereum Foundation\",\"Blockchain Capital\",\"Abra\",\"Dapper Labs\",\"Flipside Crypto\",\"BlockTower Capital\",\"Fasset\",\"WonderFi\",\"Yield Guild Games Southeast Asia\",\"Yuga Labs\",\"Bitpanda\",\"Aave\",\"Crowdz\",\"Decentraland\",\"Optimism\",\"Prime Trust\",\"Aptos\",\"BitMart\",\"BlockApps\",\"Mina\",\"Drip Capital\",\"Figure\",\"Community Gaming\",\"RockX\",\"Stellar Development Foundation\",\"bitsCrunch\",\"Functionland\",\"STEPN\",\"Ankr\",\"Boba Network\",\"Blockmetrix\",\"Bitwise\",\"dYdX\",\"RealBlocks\",\"Rarible\",\"Enjin\",\"Okcoin\",\"Venly\",\"Dfns\",\"Roll\",\"Minka\",\"Recur\",\"KuCoin\",\"Unstoppable Domains\",\"TRM Labs\",\"Spruce\",\"Chainlink\",\"Vauld\",\"Huobi\",\"Harmony\",\"CoinTracker\",\"Core Scientific\",\"Arweave\",\"ConsenSys\",\"Wirex\",\"Tangany\",\"Forte\",\"Mythical Games\",\"Zenith Chain\",\"BlockFi\",\"Storj\",\"Ancient8\",\"Aleo\",\"OneOf\",\"Stacks\",\"Propy\",\"Dune Analytics\",\"Hyperithm\",\"Gauntlet\",\"Celo\",\"Chia Network\",\"Yield Guild Games\"]\n",
    "top100CompaniesDf = pd.DataFrame({'name': top100Companies })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsPerCompany = allJobs.groupby(['Company Name'])[['Company Name']].size().reset_index(name='count').sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = fuzzy_merge(top100CompaniesDf, jobsPerCompany, 'name', 'Company Name', threshold=80, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = finalDf.merge(jobsPerCompany, left_on='matches', right_on='Company Name', how='left').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_csv('matched_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
